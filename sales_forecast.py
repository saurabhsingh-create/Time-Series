# -*- coding: utf-8 -*-
"""Sales forecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eEfegm-s9b53CiH3Uk0JR4VPFmOjKE8w
"""

!pip install pystan
!pip install fbprophet
import fbprophet
from fbprophet import Prophet
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
import os
print(os.getcwd())
import matplotlib.pyplot as plt


from datetime import datetime
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

data = pd.read_excel("Demand Planning- Assignment.xlsx",sheet_name = "Data", skiprows=2)

def transform_raw_data(df):
    df.columns = df.iloc[0,:]
    df =df.iloc[2:,2:df.shape[1]-1].reset_index(drop = True).set_index("Hour")
    col_map = df.columns
    df = df.T
    df.reset_index(inplace = True)
    df.rename({0: "Date2"}, inplace = True, axis=1)
    df.head()
    df =df.melt(id_vars=["Date2"], 
            var_name="hour", 
            value_name="Sales")
    return df,col_map

df1,cols_for_mapping = transform_raw_data(data)
df1.head()

cols_for_mapping

def create_template(sd, ed, hours_st, hours_et):
    tm =pd.Series(pd.date_range(start= sd,end=ed))
    temp = pd.concat([tm, pd.Series(cols_for_mapping)], axis =1)
    temp.columns = ["Date1", "Date2"]
    temp['key'] =0
    # date_list
    hours = pd.DataFrame({'hour':list((range(hours_st, hours_et)))})
    hours["key"] = 0
    temp =  temp.merge(hours,on='key', how='outer')
    return temp

temp_df = create_template(sd = "2021-09-06", ed = "2021-10-24", hours_st =0, hours_et = 24)

temp_df.drop(columns = ["key"], inplace = True)
temp_df = temp_df.merge(df1, on = ["Date2", "hour"], how = "left" )
temp_df["Sale_hour"] = np.where(temp_df.Sales.isnull(), 0,1)
temp_df.Sales = temp_df.Sales.fillna(0)
temp_df.drop("Date2", axis =1, inplace = True)
temp_df["ds"] = pd.to_datetime(temp_df['Date1']+pd.to_timedelta(temp_df['hour'],unit='h'))
temp_df['weekday'] = temp_df['ds'].dt.dayofweek
temp_df["Sunday_flag"] = np.where(temp_df['weekday'] ==6,1, 0)
temp_df["Public_holiday_flag"] = np.where(temp_df.Date1.isin(['2021-09-10', '2021-10-02','2021-10-15','2021-10-19']),1, 0)
temp_df.head(10)

temp_df = temp_df[temp_df['Sale_hour']==1]
final_df = temp_df[['ds', 'Sales',	'Sunday_flag', 'Public_holiday_flag']]
final_df.rename(columns = {"Sales":"y"}, inplace = True)
train=final_df[final_df['ds'] < '2021-10-11']
test=final_df[(final_df['ds'] >= '2021-10-11')]
print(train.shape)
print(test.shape)
final_df.head(10)

"""Prophet filtered table"""

from google.colab import files
final_df.to_csv('ts_data.csv') 
files.download('ts_data.csv')

plt.style.use("fivethirtyeight")
 
plt.figure(figsize=(18, 10))
plt.xlabel("ds")
plt.ylabel("Sales")
plt.title("Hourly Sales Plot") 
plt.plot(temp_df.ds,temp_df.Sales)
plt.show()

# final_df = temp_df[['ds', 'Sales','Sale_hour'	,	'Sunday_flag', 'Public_holiday_flag']]
# final_df = temp_df[['ds', 'Sales',	'Sunday_flag', 'Public_holiday_flag']]
# final_df.rename(columns = {"Sales":"y"}, inplace = True)
# final_df.head()

# train=final_df[final_df['ds'] < '2021-10-11']
# test=final_df[(final_df['ds'] >= '2021-10-11')]
# print(train.shape)
# print(test.shape)
test.head()

m = Prophet(interval_width=0.95,weekly_seasonality=True,daily_seasonality=True)
#m.add_regressor('Sale_hour',standardize=False)
# m.add_regressor('Sunday_flag',standardize=False, mode = 'multiplicative')
# m.add_regressor("Public_holiday_flag",standardize=False, mode = 'multiplicative')

m.fit(train)

test[['ds']].tail()

# future = m.make_future_dataframe(periods=336, freq='H')
future = final_df[['ds']]

future.tail()

# # future['Sale_hour'] = final_df['Sale_hour']
# future['Sunday_flag'] = final_df['Sunday_flag']
# future['Public_holiday_flag'] = final_df['Public_holiday_flag']



forecast = m.predict(future)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()

fig1 = m.plot(forecast)

fig2 = m.plot_components(forecast)

from statsmodels.tools.eval_measures import rmse
from sklearn.metrics import mean_absolute_percentage_error
def percentage_error(actual, predicted):
    res = np.empty(actual.shape)
    for j in range(actual.shape[0]):
        if actual[j] != 0:
            res[j] = (actual[j] - predicted[j]) / actual[j]
        else:
            res[j] = predicted[j] / np.mean(actual)
    return res

def mape(y_true, y_pred): 
    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100

predictions = forecast[['ds','yhat']].iloc[455:,:]
pred = predictions['yhat']
print(test['y'].mean())
print(rmse( test['y'], pred))
print(mape(test['y'], pred))
# mean_absolute_percentage_error(test['y'], pred)

op1 = pd.concat([test['ds'].reset_index(drop = True), test['y'].reset_index(drop = True), pred.reset_index(drop = True)], axis=1)
# test['ds'].reset_index(drop = True), test['y'].reset_index(drop = True),
from google.colab import files
op1.to_csv('output1.csv') 
files.download('output1.csv')

"""Predict Future"""

temp =pd.DataFrame(pd.date_range(start= "2021-10-25",end="2021-11-08"), columns = ["Date"])
temp['key'] =0
hours = pd.DataFrame({'hour':list((range(7, 20)))})
hours["key"] = 0
forecast_df =  temp.merge(hours,on='key', how='outer')

forecast_df.drop(columns = ["key"], inplace = True)
forecast_df["ds"] = pd.to_datetime(forecast_df['Date']+pd.to_timedelta(forecast_df['hour'],unit='h'))
# forecast_df.tail(2)
# temp

future = forecast_df[['ds']]

future.tail()

m = Prophet(interval_width=0.95,weekly_seasonality=True,daily_seasonality=True)
m.fit(final_df)
forecast = m.predict(future)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()
fig1 = m.plot(forecast)

#Forecast
fb_op = pd.concat([forecast_df['ds'].reset_index(drop = True), pred.reset_index(drop = True)], axis=1)
# test['ds'].reset_index(drop = True), test['y'].reset_index(drop = True),
from google.colab import files
fb_op.to_csv('fb_forecast.csv') 
files.download('fb_forecast.csv')



"""ARIMA"""

# ARIMA has AR, MA , int. AR: previous values, MA: past errors, integ : diff
!pip install pmdarima
# from typing import Literal
from statsmodels.tsa.arima_model import ARIMA
# import pmdarima as pm
from pmdarima import auto_arima
stepwise_fit = auto_arima(final_df.y, trace = True, suppress_warnings = True)
stepwise_fit.summary()

#minimize AIC

# ARIMA(0,1,1)
from statsmodels.tsa.arima_model import ARIMA
model = ARIMA(train.y, order =(1,1,3)).fit()
model.summary()

# model.forecast(20)
model.plot_predict()
plt.show()
model.forecast(60)[0]

y_pred = pd.Series(model.forecast(182)[0], index = test.ds)
y_pred

# plt.plot(test.y)
# plt.plot(y_pred)
# plt.show()

pd.DataFrame({"actual": test.y, 
              "predicted": model.forecast(182)[0]})

# predictions = forecast[['ds','yhat']].iloc[455:,:]
# pred = predictions['yhat']
print(test['y'].mean())
print(rmse( test['y'], y_pred))
print(mape(test['y'], y_pred))



"""Exponential Smoothing"""

# Seasonality decomposition
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.seasonal import seasonal_decompose 
# holt winters 
# single exponential smoothing
from statsmodels.tsa.holtwinters import SimpleExpSmoothing   
# double and triple exponential smoothing
from statsmodels.tsa.holtwinters import ExponentialSmoothing

train_ets = train.copy()
train_ets = train_ets.iloc[:,:2]
train_ets.set_index("ds", inplace = True)
# train_ets

test_ets = test.copy()
test_ets = test_ets.iloc[:,:2]
test_ets.info()
test_ets.set_index("ds", inplace = True)
# test_ets

train_ets['pred2_ADD'] = ExponentialSmoothing(train_ets['y'],trend='add').fit(smoothing_level=0.8,use_brute=True).fittedvalues
train_ets['pred2_MUL'] = ExponentialSmoothing(train_ets['y'],trend='mul').fit(smoothing_level=0.8,use_brute=True).fittedvalues
train_ets[['y','pred2_ADD','pred2_MUL']].plot(title='Holt Winters Double Exponential Smoothing: Additive and Multiplicative Trend')
print(alpha)

ets_model = ExponentialSmoothing(train_ets['y'],trend='mul', seasonal = 'mul',seasonal_periods=13).fit(smoothing_level=0.5,use_brute=True)
test_predictions = ets_model.forecast(182)
test_predictions
# len(test)

# test_ets['y'].plot(legend=True)
test_predictions.plot(legend=True)
len(test_predictions)

print(test['y'].mean())
print(rmse( test['y'], test_predictions))
print(mape(test['y'], test_predictions))

ets3 = pd.concat([test['ds'].reset_index(drop = True), test['y'].reset_index(drop = True), test_predictions.reset_index(drop = True)], axis=1)
ets3.columns = ['time', 'actual', 'predicted']
from google.colab import files
ets3.to_csv('output3.csv') 
files.download('output3.csv')

